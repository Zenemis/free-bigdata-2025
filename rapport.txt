Idée générale :
    - Utiliser le pattern de filtrage sur les "Battle"
    - Ainsi, on surcharge la méthode "Equals" de Battle pour définir
      la relation d'égalité entre deux batailles selon nos termes de
      filtrage
    - Pour pouvoir faire des "Battle" des clés Hadoop, on les fait 
      hériter de l'interface WritableComparable, et donc immplémenter
      les méthodes "write", "readFields" et "compareTo".
    - Le format d'entrée est en JSON, donc on utilise les annotations
      Jackson pour permettre la sérialisation/déserialisation
    - On crée une notion de "validité" pour chaque objet. Si cet objet
      n'est pas valide, il n'est pas considéré à l'écriture dans HDFS
    - On calcule dynamiquement le nombre de reducers à partir de la 
      taille du fichier d'entrée

Pour un WarClan :
    - Tous les attributs doivent être égaux
    
Pour un Player :
    - Un joueur n'est pas considéré seulement selon son tag, mais selon
      sa configuration totale au moment de la bataille. Ainsi, on
      considère tous ses attributs pour l'égalité, et en particulier
      le deck
    - Un joueur n'ayant pas de tour configurée se retrouve avec une
      tour "6e" par défaut
    - Les opérations et le stockage des strings est plus lourd que
      celui des int. Or les decks sont représentées par des valeurs
      hexadécimales, mais sous forme de mots dans les JSON. Nous les
      transformons en entier. On remarque qu'un entier peut stocker
      tout juste un deck, il est donc important de retirer les joueurs
      avec deck incomplet de notre jeu de données pour ne pas avoir
      d'ambigüité entre, par exemple :
      * 00223e3f42486972 (deck valide)
      *   223e3f42486972 (deck invalide)


Pour une Battle :
    - Puisque les données de 2v2 sont exclues, on passe d'une liste
      de joueurs dans Battle à 2 attributs: player1 et player2
    - Les attributs relatifs au mode de jeu (mode, game, round, WarClan)
      sont comparés simplement pour l'égalité
    - Les joueurs sont comparés vice-versa (this.p1 == other.p2 ?)
    - Deux dates sont considérées égales si elles tombent dans le
      epsilon de 10 s
    - On essaie de réfuter l'égalité le plus tôt possible, en comparant
      les éléments les plus probables d'être différents et les types
      ayant la comparaison la plus rapide en cycle
    - Puisqu'une "Battle" peut ne pas posséder une "WarClan", mais que
      le schéma d'une "Battle" doit être constant et valide pour toute
      instance afin de pouvoir la lire/écrire sur HDFS, on utilise
      une méthode qui écrit une "WarClan" vide.

Performances et ressources :
    - Ratio taille/temps CPU
      Small  : 58,4 Mo -> 49,0s CPU
      Middle : 1,59 Go -> 16min CPU
      Big    : 3,67 Go -> 37min CPU
      De Small à Middle, fichier 27x plus lourd et 19x plus de temps CPU
      De Middle à Big, fichier 2,303x plus lourd et 2,3 plus de temps CPU
    - Ratio input/output
      Small  : 100000/89302    -> 12% de réduction
      Middle : 2781989/2590967 -> 7% de réduction
      Big    : 6393303/5952326 -> 7% de réduction
    - Ratio tailles entrée/sortie
      Small  : 58 Mo/16 Mo     -> x3.6
      Middle : 1.59 Go/667 Mo  -> x2.39
      Big    : 3.67 Go/1.59 Go -> x2.31
    - Mappers bien plus lents et lourds que reducers
    - Phase shuffle lourde (24 / 58 Mo) : potentiel goulot d'étranglement
    - 

Questions :
    - Que faire si même game, mais incohérence sur le gagnant ?
    - Déléguer la partie filtrage au reduce plutôt qu'au map pour gagner
      en performances ?
    - Nous avons des résultats curieux sur le ratio nb_reads/nb_writes,
      quels sont les résultats attendus ?
    - Comment optimiser le nombre de reducers ?
